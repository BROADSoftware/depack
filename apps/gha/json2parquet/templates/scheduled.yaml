---
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: ScheduledSparkApplication
metadata:
  # Used as the driver name prefix
  name: {{ .Values.json2parquet.appName }}
  namespace: spark1
spec:
  schedule: "{{ .Values.json2parquet.schedule }}"
  concurrencyPolicy: Forbid
  successfulRunHistoryLimit: 2
  failedRunHistoryLimit: 3
  template:
    type: Scala
    mode: cluster
    image: {{ .Values.json2parquet.image }}
    imagePullPolicy: {{ .Values.json2parquet.imagePullPolicy  }}
    mainClass: "gha2spark.Json2Parquet"
    #mainApplicationFile: "s3a://spark/jars/gha2spark-0.1.0-uber.jar"
    mainApplicationFile: "{{ .Values.json2parquet.minio.serverUrl }}/spark/jars/gha2spark-0.1.0-uber.jar"
    sparkVersion: "{{ .Values.json2parquet.sparkVersion }}"
    restartPolicy:
      type: Never
    arguments:
      - --backDays
      - "{{ .Values.json2parquet.backDays }}"
      - --maxFiles
      - "{{ .Values.json2parquet.maxFiles }}"
      - --waitSeconds
      - "{{ .Values.json2parquet.waitSeconds }}"
      - --srcBucketFormat
      - {{ .Values.json2parquet.srcBucketFormat }}
      - --dstBucketFormat
      - {{ .Values.json2parquet.dstBucketFormat }}
      - --dstObjectFormat
      - {{ "raw/year={{year}}/month={{month}}/day={{day}}/hour={{hour}}" }}
      - --appName
      - {{ .Values.json2parquet.appName }} # Will be used for executor name prefix
      # The following does not work. Seems 'arguments' are not interpolated with env variable.
      # So, the variable fetching is handled in the code of the application.
      # - --s3Endpoint
      # - "${S3_ENDPOINT}"
    sparkConf:
      "spark.kubernetes.file.upload.path": "s3a://spark/shared"
      "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
      "spark.hadoop.fs.s3a.fast.upload": "true"
      "spark.hadoop.fs.s3a.path.style.access": "true"
      "spark.eventLog.enabled": "true"
      "spark.eventLog.dir": "s3a://spark/eventlogs"
    driver:
      env:
        - name: S3_ENDPOINT
          valueFrom:
            secretKeyRef:
              name: minio-server
              key: serverUrl
        - name: S3_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-server
              key: accessKey
        - name: S3_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: minio-server
              key: secretKey
      cores: {{ .Values.json2parquet.driver.cores }}
      coreLimit: "{{ .Values.json2parquet.driver.coreLimit }}"
      memory: "{{ .Values.json2parquet.driver.memory }}"
      labels:
        version: "{{ .Values.json2parquet.sparkVersion }}"
      serviceAccount: {{ .Values.json2parquet.driver.serviceAccount }}
    executor:
      instances: {{ .Values.json2parquet.executor.instances }}
      cores: {{ .Values.json2parquet.executor.cores }}
      coreLimit: "{{ .Values.json2parquet.executor.coreLimit }}"
      memory: "{{ .Values.json2parquet.executor.memory }}"
      labels:
        version: "{{ .Values.json2parquet.sparkVersion }}"
